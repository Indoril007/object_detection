{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as mpimg\n",
    "\n",
    "import utils\n",
    "from regions.selectivesearch_answer import selective_search\n",
    "# from regions.selectivesearch import selective_search\n",
    "\n",
    "import chainer\n",
    "from chainercv.links import FeaturePredictor\n",
    "from chainercv.links import VGG16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# PARAMETERS #\n",
    "##############\n",
    "\n",
    "# MODEL PATH ON SERVER\n",
    "MODEL_PATH = '/data/unagi0/dataset/rinkou/vgg16_imagenet_convert_2017_07_18.npz'\n",
    "if (not os.path.exists(MODEL_PATH)):\n",
    "    MODEL_PATH = './vgg16_imagenet_convert_2017_07_18.npz'\n",
    "if (not os.path.exists(MODEL_PATH)):\n",
    "    print(\"Please download .npz model file to the project directory\")\n",
    "\n",
    "# SELECTIVE-SEARCH PARAMETERS\n",
    "SS_PARAMS = {\"SCALE\": 250,\n",
    "            \"SIGMA\": 0.9,\n",
    "            \"MIN_SIZE\": 50,\n",
    "            \"MIN_REGION\": 2000,\n",
    "            \"MAX_RATIO\": 2}\n",
    "\n",
    "IOU_THRESHOLD = 0.3\n",
    "\n",
    "CONF_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read and Display image\n",
    "img = mpimg.imread(\"./test_images/ILSVRC2012_val_00018556.JPEG\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up a image copy and some toy bbox/confidence examples\n",
    "img_copy = img.copy()\n",
    "bboxes = [[70,300,115,460], [70,250,90,380], [140,300,95,400], [100,150,100,200], [40,300,40,330],[310,350,70,270]]\n",
    "confidences = [0.95, 0.7, 0.8, 0.6, 0.8, 0.3]\n",
    "\n",
    "# Display bboxes\n",
    "for bbox in bboxes:\n",
    "    x1, x2, y1, y2 = bbox\n",
    "    cv2.rectangle(img_copy, (x1, y1), (x2, y2), 0xFF3333, thickness=2)\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TASK 1 ##\n",
    "# FINDING THE INTERSECTION #\n",
    "def get_overlap(boxA, boxB):\n",
    "    A_x1, A_x2, A_y1, A_y2 = boxA\n",
    "    B_x1, B_x2, B_y1, B_y2 = boxB\n",
    "    \n",
    "    ## ============================= TO BE COMPLETED ============================= ##\n",
    "    ## overlap is a bounding box of form [x1, x2, y1, y2]\n",
    "    ## IF THERE IS NO OVERLAP YOU SHOULD RETURN [0,0,0,0]\n",
    "       \n",
    "    return overlap\n",
    "\n",
    "# sample randomle from bboxes\n",
    "i, j = random.sample(range(6),2)\n",
    "x1,x2,y1,y2 = get_overlap(bboxes[i], bboxes[j])\n",
    "\n",
    "# plot the two bboxes\n",
    "img_copy = img.copy()\n",
    "cv2.rectangle(img_copy, (bboxes[i][0], bboxes[i][2]), (bboxes[i][1], bboxes[i][3]), 0xFF3333, thickness=2)\n",
    "cv2.rectangle(img_copy, (bboxes[j][0], bboxes[j][2]), (bboxes[j][1], bboxes[j][3]), 0xFF3333, thickness=2)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_copy)\n",
    "\n",
    "# fill in the intersection\n",
    "cv2.rectangle(img_copy, (x1, y1), (x2, y2), 0x33FF33, thickness=-1)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TASK 2 ##\n",
    "# FIND INTERSECTION OVER UNION - IOU #\n",
    "def get_iou(boxA, boxB):\n",
    "    overlap = get_overlap(boxA, boxB)\n",
    "    \n",
    "    A_x1, A_x2, A_y1, A_y2 = boxA\n",
    "    B_x1, B_x2, B_y1, B_y2 = boxB\n",
    "    O_x1, O_x2, O_y1, O_y2 = overlap\n",
    "    \n",
    "    ## ============================= TO BE COMPLETED ============================= ##\n",
    "    ## FILL IN CALCULATION FOR IOU HERE ##\n",
    "    boxA_area = # FILL IN #\n",
    "    boxB_area = # FILL IN #\n",
    "    overlap_area = # FILL IN #\n",
    "    \n",
    "    union_area = # FILL IN #\n",
    "    iou = overlap_area / union_area\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# sample randomle from bboxes\n",
    "i, j = random.sample(range(6),2)\n",
    "\n",
    "# plot the two bboxes\n",
    "img_copy = img.copy()\n",
    "cv2.rectangle(img_copy, (bboxes[i][0], bboxes[i][2]), (bboxes[i][1], bboxes[i][3]), 0xFF3333, thickness=2)\n",
    "cv2.rectangle(img_copy, (bboxes[j][0], bboxes[j][2]), (bboxes[j][1], bboxes[j][3]), 0xFF3333, thickness=2)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_copy)\n",
    "\n",
    "print(get_iou(bboxes[i], bboxes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TASK 3 ##\n",
    "# NON MAX SUPRESSION #\n",
    "def nms(bboxes, confidences, threshold):\n",
    "    \n",
    "    # get indexes of sorted scores from greatest to lowest confidence\n",
    "    idxs = np.argsort(confidences)\n",
    "    idxs = idxs[::-1]\n",
    "    suppress = set()\n",
    "\n",
    "    ## ============================= TO BE COMPLETED ============================= ##\n",
    "    ## HINTS AVAILABLE IN CELL BELOW\n",
    "    \n",
    "    # Takes the set different between all indexes and suprressed indexes\n",
    "    pick = set(range(len(bboxes))) - suppress\n",
    "    \n",
    "    return list(pick)\n",
    "\n",
    "picks = nms(bboxes, confidences, 0.3)\n",
    "img_copy = img.copy()\n",
    "for pick in picks:\n",
    "    bbox = bboxes[pick]\n",
    "    cv2.rectangle(img_copy, (bbox[0], bbox[2]), (bbox[1], bbox[3]), 0xFF3333, thickness=2)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_copy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    for i, ??? in enumerate(idxs):\n",
    "#        if ??? in suppress:\n",
    "#            continue\n",
    "#        for ??? in idxs[i+1:]:\n",
    "#            if ??? in suppress:\n",
    "#                continue\n",
    "#            \n",
    "#            iou = get_iou(bboxes[???], bboxes[???])\n",
    "#            if (iou > threshold):\n",
    "#                suppress.add(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LETS TEST OUR CODE AND SEE IF IT WORKS ON SOME REAL EXAMPLES ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_paths = ['./test_images/ILSVRC2012_val_00004995.JPEG', './test_images/ILSVRC2012_val_00046368.JPEG']\n",
    "# Load and Display images\n",
    "imgs = utils.get_images(image_paths, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performs selective search using function \"selective_search\"\n",
    "# perform_selectivesearch appends bboxes to img[\"bboxes\"] and cropped regions to img[\"cropped_regions\"]\n",
    "utils.perform_selectivesearch(selective_search, imgs, SS_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize VGG16 classifier model\n",
    "extractor = VGG16(1000, MODEL_PATH)\n",
    "model = FeaturePredictor(extractor, crop_size=224, scale_size=256, crop='center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# perform_classification appends class predictions to img[\"classes\"] and confidences to img[\"confidences\"]\n",
    "utils.perform_classification(model, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Perform non maximum supression on bounding boxes. For regions havin an overlap exceeding the threshold\n",
    "# The region with the lower confidence score will be suppressed\n",
    "for img in imgs:\n",
    "    img[\"selected_regions\"] = nms(img[\"bboxes\"], img[\"confidences\"], IOU_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display Detected Regions and Classes\n",
    "utils.display_detections(imgs, CONF_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jtkr]",
   "language": "python",
   "name": "conda-env-jtkr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
